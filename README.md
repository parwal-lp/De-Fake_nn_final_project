# Neural Networks Final Project
### Implementation of the study: <br> ***["DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image GenerationModels"](https://arxiv.org/abs/2210.06998)* <br> by Zeyang Sha, Zheng Li, Ning Yu, Yang Zhang**

**Name**: *Laura Papi*<br>
**Matricola**: *1760732*


# Project Description

The above cited study focuses on the growing concerns about the possible misuse of AI generated images, and assesses the necessity for a tool to detect, and attribute, these fake images.<br>
In particular, it points out the lack of research on the particular case of images generated by a text prompt.
<br>

<br>
Therefore, this research proposes methods to answer the following 3 research questions [RQ]:

- **RQ1**. Detection of images generated by text-to-image generation models

- **RQ2**. Attribution of the fake images to their source model

- **RQ3**. Analysis of the likelihood that different text prompts have to generate authentic images
<br>

The methods implemented in this repository aim to answer to the first two questions (RQ1 and RQ2).

Instructions on how to run and test the models, using pre-built datasets and pre-trained weights can be found in the [Notebook](tldr_notebook.ipynb).<br>
The full description of the work, including data fetching, dataset building, model design and training, can be found in the [Complete Notebook](complete_notebook.ipynb). This can be used to reproduce from scratch all the work of this project.
<br>
The complete code of this project can be found in the source directory of this GitHub repository [Source Code](https://github.com/parwal-lp/De-Fake_nn_final_project/tree/main/src).


## Prerequisites
This project was implemented using Python 3.8.10.
This sections contains the prerequisites for running both the notebooks.

The following is needed for both the notebooks:
- Clone this repository
    ```
    git clone https://github.com/parwal-lp/De-Fake_nn_final_project.git
    ```
- Install pandas
    ```
    pip install pandas
    ```
- Install Torchvision library
    ```
    pip install torchvision
    ```
- Install the CLIP model (from OpenAI, required to encode images and captions for the hybrid models' datasets)
    ```
    pip install ftfy regex tqdm
    ```

If you only need to run the [Notebook](tldr_notebook.ipynb) then you can skip the next instructions.<br>
If instead you want to run the [Complete Notebook](complete_notebook.ipynb), then you will also need the following:
- Install Stable Diffusion sdk, necessary to generate fake images using SD
    ```
    pip install stability-sdk
    ```
- Register to the [Stable Diffusion website](https://platform.stability.ai/) and obtain an API key (credit for at least 400 images is needed).
- Install Latent Diffusion model from GitHub, necessary to generate fake images using LD
    ```
    git clone https://github.com/CompVis/latent-diffusion.git
    pip install transformers==4.19.2 scann kornia==0.6.4 torchmetrics==0.6.0
    pip install omegaconf
    pip install einops
    pip install pytorch_lightning
    pip install taming-transformers-rom1504
    ```
- Copy the file "src/txt2img_batch.py" ([link to the file](src/txt2img_batch.py)) into your installation folder of Latent Diffusion, at the path "latent-diffusion/scripts/".<br>
This file provides an alternative way to run LD to generate images. The original method of the official LD repository allows to generate one image at a time, reloading the model for every generation.<br>
For the purposes of this project LD is needed to generate a high number of images in sequence, and reloading the model for each one is definitely not efficient.<br>
This custom script allows to run LD by passing a dictionary of text prompts as input, LD will then generate an image for each prompt in the dictionary, loading the model only once at the beginning.<br><br>
- If you do not have a CUDA device available for computation, you can still run Latent Diffusion on the cpu, but you will first need to modify its files according to the following commit:<br>
    https://github.com/CompVis/latent-diffusion/pull/123/files<br>
    If you have a CUDA device available, skip this step.<br><br>
- Install GLIDE model from GitHub, necessary to generate fake images using GLIDE
    ```
    git clone https://github.com/openai/glide-text2im.git
    cd glide-text2im/
    pip install -e .
    pip install nbformat
    ```
- Download the [MSCOCO annotations](images.cocodataset.org/annotations/annotations_trainval2017.zip), needed to fetch real images for the training dataset.<br>
    Extract the downloaded folder and place it at the root of this repository.<br><br>
