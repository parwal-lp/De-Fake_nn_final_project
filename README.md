# Neural Networks Final Project
### Implementation of the study: <br> ***"DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image GenerationModels"* <br> by Zeyang Sha, Zheng Li, Ning Yu, Yang Zhang**

**Name**: *Laura Papi*<br>
**Matricola**: *1760732*


# Project Description

The above cited study focuses on the growing concerns about the possible misuse of AI generated images, and assesses the necessity for a tool to detect, and attribute, these fake images.<br>
In particular, it points out the lack of research on the particular case of images generated by a text prompt.
<br>

<br>
Therefore, this research proposes methods to answer the following 3 research questions [RQ]:

- **RQ1**. Detection of images generated by text-to-image generation models

- **RQ2**. Attribution of the fake images to their source model

- **RQ3**. Analysis of the likelihood that different text prompts have to generate authentic images
<br>

Instructions on how to run and test the models, using pre-built datasets and pre-trained weights can be found in the [Notebook](tldr_notebook.ipynb).<br>
The complete description of the work, including data fetching, dataset building, model design and training, can be found in the [Complete Notebook](complete_notebook.ipynb). This can be used to reproduce from scratch all the work of this project.
<br>
The complete code of this project can be found in the source directory of this GitHub repository [Source Code](https://github.com/parwal-lp/De-Fake_nn_final_project/src).


## Prerequisites
This project was implemented using Python 3.8.10.

- install pandas
    ```
    pip install pandas
    ```
- install Stable Diffusion sdk
    ```
    pip install stability-sdk
    ```
- install Torchvision library
    ```
    pip install torchvision
    ```
- install Latent Diffusion model from GitHub
    ```
    git clone https://github.com/CompVis/latent-diffusion.git
    pip install transformers==4.19.2 scann kornia==0.6.4 torchmetrics==0.6.0
    pip install omegaconf
    pip install einops
    pip install pytorch_lightning
    pip install taming-transformers-rom1504
    ```
- install GLIDE model from GitHub
    ```
    git clone https://github.com/openai/glide-text2im.git
    cd glide-text2im/
    pip install -e .
    pip install nbformat
    ```
- install CLIP (from OpenAI, required to encode images and captions for the hybrid models)
    ```
    pip install ftfy regex tqdm
    ```
- modify the latent-diffusion files according to the commit<br>
    https://github.com/CompVis/latent-diffusion/pull/123/files<br>
    in order to be able to run the model on cpu only<br><br>
- download the [MSCOCO annotations](images.cocodataset.org/annotations/annotations_trainval2017.zip).<br>
    Extract the downloaded folder and place it at the root of this repository.<br><br>
- Register to [Stable Diffusion](https://platform.stability.ai/) and obtain an API key.