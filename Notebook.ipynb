{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Final Project\n",
    "### Reimplementation of the study: <br> ***\"DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image GenerationModels\"* <br> from Zeyang Sha, Zheng Li, Ning Yu, Yang Zhang**\n",
    "\n",
    "**Name**: *Laura Papi*\n",
    "\n",
    "**Matricola**: *1760732*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "The above cited study focuses on the growing concerns about the possible misuse of AI generated images, and assesses the necessity for a tool to detect, and attribute, these fake images.<br>\n",
    "In particular, it points out the lack of research on the particular case of images generated by a text prompt.\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "Therefore, this research proposes methods to answer the following 3 research questions [RQ]:\n",
    "\n",
    "- **RQ1**. Detection of images generated by text-to-image generation models\n",
    "\n",
    "- **RQ2**. Attribution of the fake images to their source model\n",
    "\n",
    "- **RQ3**. Analysis of the likelihood that different text prompts have to generate authentic images\n",
    "\n",
    "<br><br>\n",
    "The following sections contain examples for my implementation of the described methods.<br><br>\n",
    "The complete implementation of the models can be found in the source directory of the GitHub repository __[Source Code](http://url)__\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1. Detection of images generated by text-to-image generation models\n",
    "\n",
    "The study proposes two detector models:\n",
    "\n",
    "1. **Image-only detector**<br>binary classifier that decides whether an input image is fake or real.\n",
    "\n",
    "2. **Hybrid detector**<br>binary classifier that is able to tell if an image is fake or real, based on the input image and its corresponding text prompt.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Image-only detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Training Dataset\n",
    "The training dataset is constitueted by a set of N real images (labeled 1), and a set of N corresponding fake generated images (labeled 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.1 Data Collection\n",
    "The data used for the training is collected and generated as described in the following steps **(i)** and **(ii)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(i)** Real images are fetched from the MSCOCO dataset, together with their captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#import the path to the scripts needed for this section\n",
    "sys.path.insert(10, '/home/parwal/Documents/GitHub/De-Fake_nn_final_project/src/imageonly_detector')\n",
    "#TODO capire a chi serve questo import e metterlo nel posto giusto\n",
    "\n",
    "\n",
    "from src.imageonly_detector.MSCOCO_data_collection import fetchImagesFromMSCOCO\n",
    "\n",
    "#fetch 200 real images from MSCOCO, each with its corresponding caption\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO/images\", \"data/MSCOCO\", 50)\n",
    "#TODO testare se funziona anche chiamato cosi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(ii)** The captions from the MSCOCO images are used as input to the Stable Diffusion (SD) text-to-image generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use stable-diffusion API to generate 200 fake images from the 200 captions collected before\n",
    "%run src/imageonly_detector/SD_MSCOCO_data_generation.py\n",
    "#TODO valutare se trasformarlo in funzione o tenerlo come run dello script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.2 Data Construction\n",
    "The collected and generated data is then shaped in the following structure, in order to be used for the training step:<br><br>\n",
    "train/<br>\n",
    "    ├── class_0/<br>\n",
    "    │   ├── ...<br>\n",
    "    │   └── all the fake images<br>\n",
    "    ├── class_1/<br>\n",
    "    │   ├── ...<br>\n",
    "    │   └── all the real images<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.imageonly_detector.format_dataset import formatIntoDataset\n",
    "\n",
    "#function that transforms the collected data in the previously described structure\n",
    "formatIntoDataset(\"data/MSCOCO/images\", \"data/SD+MSCOCO/images\", \"data/imageonly_detector_data/train\")\n",
    "#TODO testare se funzione chiamata cosi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Detector Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Testing Dataset\n",
    "The testing dataset follows the same structure of the training dataset, but in order to evaluate the generalizability of the model for the testing dataset we use different text-to-image generation models.<br>\n",
    "In particular we will test the image-only classifier on data generated by Latent Diffusion (LD), GLIDE and DALL-E2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.1 Data Collection\n",
    "Similarly as seen in **1.1.1**, the data is collected in the following two steps **(i)** and **(ii)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(i)** Real images are fetched from the MSCOCO dataset, together with their captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "print(sys.path)\n",
    "\n",
    "from src.imageonly_detector.MSCOCO_data_collection import fetchImagesFromMSCOCO\n",
    "\n",
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_LD/images\", \"data/MSCOCO_for_LD\", 50)\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_GLIDE/images\", \"data/MSCOCO_for_GLIDE\", 50)\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_DALLE2/images\", \"data/MSCOCO_for_DALLE2\", 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(ii)** The captions from the MSCOCO images are used as input to LD, GLIDE and DALL-E2 text-to-image generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "#resetto la directory corrente a quella del progetto de-fake, altrimenti il file da eseguire non viene trovato\n",
    "#questo è necessario perché LD_MSCOCO_data_generation.py cambia la directory a quella di latent-diffusion\n",
    "os.chdir(\"/home/parwal/Documents/GitHub/De-Fake_nn_final_project\")\n",
    "%run src/imageonly_detector/LD_MSCOCO_data_generation.py\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "#TODO\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3.2 Dataset Construction\n",
    "The data is structured as already seen and described in **1.1.2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "formatIntoDataset(\"data/MSCOCO_for_LD/images\", \"../latent-diffusion/outputs/txt2img-samples\", \"data/imageonly_detector_data/val_LD\") #TODO\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "#TODO\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=14.11s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "#generate the training dataset\n",
    "#fetch 200 real images from MSCOCO, each with its corresponding caption\n",
    "%run src/imageonly_detector/MSCOCO_data_collection.py\n",
    "\n",
    "#use stable-diffusion API to generate 200 fake images from the 200 captions collected before\n",
    "%run src/imageonly_detector/SD_MSCOCO_data_generation.py\n",
    "\n",
    "#generate the dataset needed for training\n",
    "%run src/imageonly_detector/generate_train_dataset.py\n",
    "\n",
    "#train the image-only detector on the previously generated dataset\n",
    "%run src/imageonly_detector/train.py\n",
    "\n",
    "#generate the datasets need for evaluation\n",
    "#LD+MSCOCO\n",
    "#first fetch again some pictures from \n",
    "\n",
    "#GLIDE+MSCOCO\n",
    "\n",
    "#DALL-E2+MSCOCO\n",
    "\n",
    "#evaluate the image-only detector on the three previously generated datasets\n",
    "%run src/imageonly_detector/evaluate.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hybrid detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.1 Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1.2 Dataset Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Detector Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Testing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.1 Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3.2 Dataset Construction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ2. Attribution of the fake images to their source model\n",
    "\n",
    "The study proposes two attributor models:\n",
    "\n",
    "1. **Image-only attributor**<br>multi-class classifier that assigns each input image to its source generation model.\n",
    "\n",
    "2. **Hybrid attributor**<br>multi-class classifier that assigns each input image to its source generation model, based on the input image and its corresponding text prompt.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Image-only attributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hybrid attributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ3. Analysis of the likelihood that different text prompts have to generate authentic images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
