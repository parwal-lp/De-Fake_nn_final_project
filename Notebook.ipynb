{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Final Project\n",
    "### Reimplementation of the study: <br> ***\"DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image GenerationModels\"* <br> from Zeyang Sha, Zheng Li, Ning Yu, Yang Zhang**\n",
    "\n",
    "**Name**: *Laura Papi*\n",
    "\n",
    "**Matricola**: *1760732*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "The above cited study focuses on the growing concerns about the possible misuse of AI generated images, and assesses the necessity for a tool to detect, and attribute, these fake images.<br>\n",
    "In particular, it points out the lack of research on the particular case of images generated by a text prompt.\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "Therefore, this research proposes methods to answer the following 3 research questions [RQ]:\n",
    "\n",
    "- **RQ1**. Detection of images generated by text-to-image generation models\n",
    "\n",
    "- **RQ2**. Attribution of the fake images to their source model\n",
    "\n",
    "- **RQ3**. Analysis of the likelihood that different text prompts have to generate authentic images\n",
    "\n",
    "<br><br>\n",
    "The following sections contain examples for my implementation of the described methods.<br><br>\n",
    "The complete implementation of the models can be found in the source directory of the GitHub repository __[Source Code](http://url)__\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1. Detection of images generated by text-to-image generation models\n",
    "\n",
    "The study proposes two detector models:\n",
    "\n",
    "1. **Image-only detector**<br>binary classifier that decides whether an input image is fake or real.\n",
    "\n",
    "2. **Hybrid detector**<br>binary classifier that is able to tell if an image is fake or real, based on the input image and its corresponding text prompt.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Image-only detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Dataset\n",
    "All the datasets are constitueted by a set of N real images (labeled 1), and a set of N corresponding fake generated images (labeled 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.1 Data Collection\n",
    "The data used for the training is collected and generated as described in the following steps **(i)** and **(ii)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(i)** Real images are fetched from the MSCOCO dataset, together with their captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#import the path to the scripts needed for this section\n",
    "sys.path.insert(10, '/home/parwal/Documents/GitHub/De-Fake_nn_final_project/src/imageonly_detector')\n",
    "#TODO capire a chi serve questo import e metterlo nel posto giusto\n",
    "\n",
    "from src.imageonly_detector.MSCOCO_data_collection import fetchImagesFromMSCOCO\n",
    "\n",
    "#SD+MSCOCO\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_SD/images\", \"data/MSCOCO_for_SD\", 100)\n",
    "\n",
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_LD/images\", \"data/MSCOCO_for_LD\", 50)\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_GLIDE/images\", \"data/MSCOCO_for_GLIDE\", 50)\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(ii)** The captions from the MSCOCO images are used as input to the Stable Diffusion (SD) text-to-image generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SD+MSCOCO --------------------------------------------------------------------------\n",
    "#use stable-diffusion API to generate 100 fake images from the 100 captions collected before\n",
    "#prima di eseguire il file ho cambiato le directory\n",
    "%run src/imageonly_detector/SD_MSCOCO_data_generation.py\n",
    "\n",
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "#resetto la directory corrente a quella del progetto de-fake, altrimenti il file da eseguire non viene trovato\n",
    "#questo è necessario perché LD_MSCOCO_data_generation.py cambia la directory a quella di latent-diffusion\n",
    "os.chdir(\"/home/parwal/Documents/GitHub/De-Fake_nn_final_project\")\n",
    "%run src/imageonly_detector/LD_MSCOCO_data_generation.py\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "#NON HO MAI PROVATO A RUNNARLO, altrimenti rigenera il modello (3gb)\n",
    "#provare a runnarlo proprio alla fine di tutto per sicurezza\n",
    "%run src/imageonly_detector/GLIDE_MSCOCO_data_generation.ipynb\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO (è a pagamento soltanto con le API, valutare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.2 Dataset Construction\n",
    "The collected and generated data is then shaped in the following structure, in order to be used for the training and evaluation step:<br><br>\n",
    "train/<br>\n",
    "    ├── class_0/<br>\n",
    "    │   ├── ...<br>\n",
    "    │   └── all the fake images<br>\n",
    "    ├── class_1/<br>\n",
    "    │   ├── ...<br>\n",
    "    │   └── all the real images<br>\n",
    "val/<br>\n",
    "    ├── class_0/<br>\n",
    "    │   ├── ...<br>\n",
    "    │   └── all the fake images<br>\n",
    "    ├── class_1/<br>\n",
    "    │   ├── ...<br>\n",
    "    │   └── all the real images<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the collected data in the previously described structure\n",
    "\n",
    "from src.imageonly_detector.format_dataset import formatIntoDataset, formatIntoTrainTest\n",
    "\n",
    "#SD+MSCOCO\n",
    "#this function generates a pair of datasets (train and val), starting from data from the Stable Diffusion generation\n",
    "#the data generated from SD contains 100 images, this original dataset is split in half (50 for train, 50 for test)\n",
    "formatIntoTrainTest(\"data/MSCOCO_for_SD/images\", \"data/SD+MSCOCO/images\", \"data/imageonly_detector_data\")\n",
    "print(\"ok SD\")\n",
    "\n",
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "formatIntoDataset(\"data/MSCOCO_for_LD/images\", \"../latent-diffusion/outputs/txt2img-samples\", \"data/imageonly_detector_data/val_LD\")\n",
    "print(\"ok LD\")\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "formatIntoDataset(\"data/MSCOCO_for_GLIDE/images\", \"data/GLIDE+MSCOCO/images\", \"data/imageonly_detector_data/val_GLIDE\")\n",
    "print(\"ok GLIDE\")\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO (è a pagamento soltanto con le API, valutare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Detector\n",
    "\n",
    "The model is defined and trained in the file executed in the followind code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function trains the model and tests it at every epoch\n",
    "#both the test and train datasets are generated using SD\n",
    "%run src/imageonly_detector/train.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hybrid detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Dataset\n",
    "\n",
    "The dataset is built in the exact same way as the dataset for the image-only detector.\n",
    "The following are the instructions to run in order to build:\n",
    "- one training dataset (using images generated from SD)\n",
    "- three evaluation dataset (using images generated from SD, LD and GLIDE respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# N.B.\n",
    "# before running this block you need to erase all the content of the following directories:\n",
    "# data/MSCOCO_for_SD\n",
    "# data/MSCOCO_for_LD\n",
    "# data/MSCOCO_for_GLIDE\n",
    "# data/SD+MSCOCO\n",
    "# data/GLIDE+MSCOCO\n",
    "# latent-diffusion/outputs/txt2img-samples\n",
    "\n",
    "# ------------------- COLLECT REAL IMAGES FROM MSCOCO -------------------- #\n",
    "#import the path to the scripts needed for this section\n",
    "sys.path.insert(10, '/home/parwal/Documents/GitHub/De-Fake_nn_final_project/src/imageonly_detector')\n",
    "#TODO capire a chi serve questo import e metterlo nel posto giusto\n",
    "\n",
    "from src.imageonly_detector.MSCOCO_data_collection import fetchImagesFromMSCOCO\n",
    "\n",
    "#SD+MSCOCO\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_SD/images\", \"data/MSCOCO_for_SD\", 100)\n",
    "\n",
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_LD/images\", \"data/MSCOCO_for_LD\", 50)\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_GLIDE/images\", \"data/MSCOCO_for_GLIDE\", 50)\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ------------------- GENERATE FAKE IMAGES USING SD, LD, GLIDE -------------------- #\n",
    "#SD+MSCOCO --------------------------------------------------------------------------\n",
    "#use stable-diffusion API to generate 100 fake images from the 100 captions collected before\n",
    "%run src/imageonly_detector/SD_MSCOCO_data_generation.py\n",
    "\n",
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "# N.B.\n",
    "# prima di lanciare questo comando, aggiungere il file src/imageonly_detector/txt2img_batch.py alla directory latent-diffusion/scripts/\n",
    "#resetto la directory corrente a quella del progetto de-fake, altrimenti il file da eseguire non viene trovato\n",
    "#questo è necessario perché LD_MSCOCO_data_generation.py cambia la directory a quella di latent-diffusion\n",
    "os.chdir(\"/home/parwal/Documents/GitHub/De-Fake_nn_final_project\")\n",
    "%run src/imageonly_detector/LD_MSCOCO_data_generation_batch.py\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "#NON HO MAI PROVATO A RUNNARLO, altrimenti rigenera il modello (3gb)\n",
    "#provare a runnarlo proprio alla fine di tutto per sicurezza\n",
    "%run src/imageonly_detector/GLIDE_MSCOCO_data_generation.ipynb #TODO\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO (è a pagamento soltanto con le API, valutare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- FORMAT THE DATA INTO THE STRUCTURE NEEDED FOR TRAINING/TESTING -------------------- #\n",
    "os.chdir(\"/home/parwal/Documents/GitHub/De-Fake_nn_final_project\")\n",
    "\n",
    "#transform the collected data in the previously described structure\n",
    "from src.imageonly_detector.format_dataset import formatIntoDataset, formatIntoTrainTest\n",
    "\n",
    "\n",
    "#SD+MSCOCO --------------------------------------------------------------------------\n",
    "#this function generates a pair of datasets (train and val), starting from data from the Stable Diffusion generation\n",
    "#the data generated from SD contains 100 images, this original dataset is split in half (50 for train, 50 for test)\n",
    "formatIntoTrainTest(\"data/MSCOCO_for_SD/images\", \"data/SD+MSCOCO/images\", \"data/hybrid_detector_data\")\n",
    "print(\"ok SD\")\n",
    "\n",
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "formatIntoDataset(\"data/MSCOCO_for_LD/images\", \"../latent-diffusion/outputs/txt2img-samples\", \"data/hybrid_detector_data/val_LD\")\n",
    "print(\"ok LD\")\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "formatIntoDataset(\"data/MSCOCO_for_GLIDE/images\", \"data/GLIDE+MSCOCO/images\", \"data/hybrid_detector_data/val_GLIDE\") #TODO\n",
    "print(\"ok GLIDE\")\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO (è a pagamento soltanto con le API, valutare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model structure is defined in src/hybrid_detector/hybrid_detector.py<br><br>\n",
    "\n",
    "The training dataset is generated using Stable Diffusion (SD), same as for the image-only detector.<br>\n",
    "It can be trained running the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function first builds the dataloader for the training datasert\n",
    "# then it trains the model and saves the trained weights in the directory trained_models/\n",
    "%run src/hybrid_detector/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is trained, we can evaluate it on some test datasets.<br>\n",
    "In particular we will evaluate it on:<br>\n",
    "- Stable Diffusion (SD), dataset generated from the same image-to-text generator used for the train dataset.\n",
    "- GLIDE\n",
    "- Latent Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the data into dataloaders suitable for the model, and run the evaluation algorithm.\n",
    "%run src/hybrid_detector/eval.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ2. Attribution of the fake images to their source model\n",
    "\n",
    "The study proposes two attributor models:\n",
    "\n",
    "1. **Image-only attributor**<br>multi-class classifier that assigns each input image to its source generation model.\n",
    "\n",
    "2. **Hybrid attributor**<br>multi-class classifier that assigns each input image to its source generation model, based on the input image and its corresponding text prompt.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Image-only attributor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Dataset\n",
    "\n",
    "The dataset is built similarly as in the previous cases, using fake images generated by text-to-image generation models.\n",
    "But in this case the goal is to train a model to classify fake images based on the model that generated them.\n",
    "So we will need to build a multi-class classifier, with each class corresponding to one model.\n",
    "\n",
    "This means that the dataset we are going to build is obtained by:\n",
    "- retrieving N captions from MSCOCO\n",
    "- using one third of the propmts per each model, to get N/3 fake images from each model\n",
    "\n",
    "This will lead us to build a dataset with the following structure:\n",
    "\n",
    "attributor_dataset/<br>\n",
    "    ├── class_SD/<br>\n",
    "    │   ├── ...<br>\n",
    "    │   └── all the images generated by SD<br>\n",
    "    ├── class_GLIDE/<br>\n",
    "    │   ├── ...<br>\n",
    "    │   └── all the images generated by GLIDE<br>\n",
    "    ├── class_LD/<br>\n",
    "    │   ├── ...<br>\n",
    "    │   └── all the images generated by LD<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.imageonly_attributor.format_dataset import format_dataset_multiclass\n",
    "from src.imageonly_attributor.dataset_generator import SD_generation, LD_generation, GLIDE_generation\n",
    "from src.imageonly_detector.MSCOCO_data_collection import fetchCaptionsFromMSCOCO\n",
    "import os\n",
    "\n",
    "proj_dir = \"../De-Fake_nn_final_project\"\n",
    "os.chdir(proj_dir)\n",
    "\n",
    "# fetch the captions (N=150)\n",
    "fetchCaptionsFromMSCOCO(\"data/imageonly_attributor_data\", 50) # TODO fix chiama la funzione giusta con i parametri giusti\n",
    "\n",
    "# use the first 50 (N/3) captions to generate images with SD\n",
    "SD_generation(\"data/imageonly_attributor_data/train/mscoco_captions.csv\", \"data/imageonly_attributor_data/generated/SD+MSCOCO\")\n",
    "\n",
    "# use other 50 (N/3) captions to generate images with GLIDE\n",
    "GLIDE_generation(\"data/imageonly_attributor_data/train/mscoco_captions.csv\", \"data/imageonly_attributor_data/generated/GLIDE+MSCOCO\")\n",
    "\n",
    "# use the last 50 (N/3) captions to generate images with LD\n",
    "LD_generation(\"data/imageonly_attributor_data/train/mscoco_captions.csv\")\n",
    "\n",
    "# move the generated images to the dataset dir\n",
    "# TODO trasforma tutte le stringhe in variabili che puo settare l'utente, con istruzioni su come settarle\n",
    "format_dataset_multiclass(\"data/imageonly_attributor_data/generated/SD+MSCOCO\", \"../latent-diffusion/outputs/txt2img-samples\", \"data/imageonly_attributor_data/generated/GLIDE+MSCOCO\", \"data/imageonly_attributor_data/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same procedure for the test dataset\n",
    "\n",
    "from src.imageonly_attributor.format_dataset import format_dataset_multiclass\n",
    "from src.imageonly_attributor.dataset_generator import SD_generation, LD_generation\n",
    "from src.imageonly_detector.MSCOCO_data_collection import fetchImagesFromMSCOCO\n",
    "\n",
    "# fetch the images with their captions from MSCOCO (N=50)\n",
    "fetchImagesFromMSCOCO(\"data/imageonly_attributor_data/test/class_real\", \"data/imageonly_attributor_data/test\", 50)\n",
    "\n",
    "# use the same 50 captions to generate images with SD\n",
    "SD_generation(\"data/imageonly_attributor_data/test/mscoco_captions.csv\", \"data/imageonly_attributor_data/generated/SD+MSCOCO_test\")\n",
    "\n",
    "# use the same 50 captions to generate images with GLIDE\n",
    "GLIDE_generation(\"data/imageonly_attributor_data/test/mscoco_captions.csv\", \"data/imageonly_attributor_data/test/GLIDE+MSCOCO_test\")\n",
    "\n",
    "# use the same 50 captions to generate images with LD OK\n",
    "LD_generation(\"data/imageonly_attributor_data/test/mscoco_captions.csv\")\n",
    "\n",
    "# move the generated images to the dataset dir\n",
    "# TODO trasforma tutte le stringhe in variabili che puo settare l'utente, con istruzioni su come settarle\n",
    "format_dataset_multiclass(\"data/imageonly_attributor_data/generated/SD+MSCOCO_test\", \"../latent-diffusion/outputs/txt2img-samples\", \"data/imageonly_attributor_data/generated/GLIDE+MSCOCO\", \"data/imageonly_attributor_data/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Attributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function trains the model and tests it at every epoch\n",
    "#both the test and train datasets are generated using MSCOCO, SD, LD, GLIDE\n",
    "%run src/imageonly_detector/train.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hybrid attributor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.imageonly_attributor.format_dataset import format_dataset_multiclass\n",
    "from src.imageonly_attributor.dataset_generator import SD_generation, LD_generation, GLIDE_generation\n",
    "from src.imageonly_detector.MSCOCO_data_collection import fetchImagesFromMSCOCO\n",
    "\n",
    "# fetch the images with their captions from MSCOCO (N=50)\n",
    "#fetchImagesFromMSCOCO(\"data/hybrid_attributor_data/train/class_real\", \"data/hybrid_attributor_data/train\", 50)\n",
    "\n",
    "# use the same 50 captions to generate images with SD\n",
    "#SD_generation(\"data/hybrid_attributor_data/train/mscoco_captions.csv\", \"data/hybrid_attributor_data/generated/SD+MSCOCO_train\")\n",
    "\n",
    "# use the same 50 captions to generate images with GLIDE\n",
    "#GLIDE_generation(\"data/hybrid_attributor_data/train/mscoco_captions.csv\", \"data/hybrid_attributor_data/generated/GLIDE+MSCOCO_train\")\n",
    "\n",
    "# use the same 50 captions to generate images with LD OK\n",
    "LD_generation(\"data/hybrid_attributor_data/train/mscoco_captions.csv\")\n",
    "\n",
    "# move the generated images to the dataset dir\n",
    "# TODO trasforma tutte le stringhe in variabili che puo settare l'utente, con istruzioni su come settarle\n",
    "format_dataset_multiclass(\"data/hybrid_attributor_data/generated/SD+MSCOCO_train\", \"../latent-diffusion/outputs/txt2img-samples\", \"data/hybrid_attributor_data/generated/GLIDE+MSCOCO_train\", \"data/hybrid_attributor_data/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.imageonly_attributor.format_dataset import format_dataset_multiclass\n",
    "from src.imageonly_attributor.dataset_generator import SD_generation, LD_generation, GLIDE_generation\n",
    "from src.imageonly_detector.MSCOCO_data_collection import fetchImagesFromMSCOCO\n",
    "\n",
    "# fetch the images with their captions from MSCOCO (N=50)\n",
    "fetchImagesFromMSCOCO(\"data/hybrid_attributor_data/test/class_real\", \"data/hybrid_attributor_data/test\", 50)\n",
    "\n",
    "# use the same 50 captions to generate images with SD\n",
    "SD_generation(\"data/hybrid_attributor_data/test/mscoco_captions.csv\", \"data/hybrid_attributor_data/generated/SD+MSCOCO_test\")\n",
    "\n",
    "# use the same 50 captions to generate images with GLIDE\n",
    "GLIDE_generation(\"data/hybrid_attributor_data/test/mscoco_captions.csv\", \"data/hybrid_attributor_data/generated/GLIDE+MSCOCO_test\")\n",
    "\n",
    "# use the same 50 captions to generate images with LD OK\n",
    "LD_generation(\"data/hybrid_attributor_data/test/mscoco_captions.csv\")\n",
    "\n",
    "# move the generated images to the dataset dir\n",
    "# TODO trasforma tutte le stringhe in variabili che puo settare l'utente, con istruzioni su come settarle\n",
    "format_dataset_multiclass(\"data/hybrid_attributor_data/generated/SD+MSCOCO_test\", \"../latent-diffusion/outputs/txt2img-samples\", \"data/hybrid_attributor_data/generated/GLIDE+MSCOCO_test\", \"data/hybrid_attributor_data/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Attributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ3. Analysis of the likelihood that different text prompts have to generate authentic images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
