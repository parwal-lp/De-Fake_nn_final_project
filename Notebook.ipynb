{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks Final Project\n",
    "### Reimplementation of the study: <br> ***\"DE-FAKE: Detection and Attribution of Fake Images Generated by Text-to-Image GenerationModels\"* <br> from Zeyang Sha, Zheng Li, Ning Yu, Yang Zhang**\n",
    "\n",
    "**Name**: *Laura Papi*\n",
    "\n",
    "**Matricola**: *1760732*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "The above cited study focuses on the growing concerns about the possible misuse of AI generated images, and assesses the necessity for a tool to detect, and attribute, these fake images.<br>\n",
    "In particular, it points out the lack of research on the particular case of images generated by a text prompt.\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "Therefore, this research proposes methods to answer the following 3 research questions [RQ]:\n",
    "\n",
    "- **RQ1**. Detection of images generated by text-to-image generation models\n",
    "\n",
    "- **RQ2**. Attribution of the fake images to their source model\n",
    "\n",
    "- **RQ3**. Analysis of the likelihood that different text prompts have to generate authentic images\n",
    "\n",
    "<br><br>\n",
    "The following sections contain examples for my implementation of the described methods.<br><br>\n",
    "The complete implementation of the models can be found in the source directory of the GitHub repository __[Source Code](http://url)__\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ1. Detection of images generated by text-to-image generation models\n",
    "\n",
    "The study proposes two detector models:\n",
    "\n",
    "1. **Image-only detector**<br>binary classifier that decides whether an input image is fake or real.\n",
    "\n",
    "2. **Hybrid detector**<br>binary classifier that is able to tell if an image is fake or real, based on the input image and its corresponding text prompt.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Image-only detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Dataset\n",
    "All the datasets are constitueted by a set of N real images (labeled 1), and a set of N corresponding fake generated images (labeled 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.1 Data Collection\n",
    "The data used for the training is collected and generated as described in the following steps **(i)** and **(ii)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(i)** Real images are fetched from the MSCOCO dataset, together with their captions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "#import the path to the scripts needed for this section\n",
    "sys.path.insert(10, '/home/parwal/Documents/GitHub/De-Fake_nn_final_project/src/imageonly_detector')\n",
    "#TODO capire a chi serve questo import e metterlo nel posto giusto\n",
    "\n",
    "from src.imageonly_detector.MSCOCO_data_collection import fetchImagesFromMSCOCO\n",
    "\n",
    "#SD+MSCOCO\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_SD/images\", \"data/MSCOCO_for_SD\", 100)\n",
    "\n",
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_LD/images\", \"data/MSCOCO_for_LD\", 50)\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_GLIDE/images\", \"data/MSCOCO_for_GLIDE\", 50)\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **(ii)** The captions from the MSCOCO images are used as input to the Stable Diffusion (SD) text-to-image generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SD+MSCOCO --------------------------------------------------------------------------\n",
    "#use stable-diffusion API to generate 100 fake images from the 100 captions collected before\n",
    "#prima di eseguire il file ho cambiato le directory\n",
    "%run src/imageonly_detector/SD_MSCOCO_data_generation.py\n",
    "\n",
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "#resetto la directory corrente a quella del progetto de-fake, altrimenti il file da eseguire non viene trovato\n",
    "#questo è necessario perché LD_MSCOCO_data_generation.py cambia la directory a quella di latent-diffusion\n",
    "os.chdir(\"/home/parwal/Documents/GitHub/De-Fake_nn_final_project\")\n",
    "%run src/imageonly_detector/LD_MSCOCO_data_generation.py\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "#NON HO MAI PROVATO A RUNNARLO, altrimenti rigenera il modello (3gb)\n",
    "#provare a runnarlo proprio alla fine di tutto per sicurezza\n",
    "%run src/imageonly_detector/GLIDE_MSCOCO_data_generation.ipynb\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO (è a pagamento soltanto con le API, valutare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.2 Dataset Construction\n",
    "The collected and generated data is then shaped in the following structure, in order to be used for the training and evaluation step:<br><br>\n",
    "train/<br>\n",
    "    ├── class_0/<br>\n",
    "    │   ├── ...<br>\n",
    "    │   └── all the fake images<br>\n",
    "    ├── class_1/<br>\n",
    "    │   ├── ...<br>\n",
    "    │   └── all the real images<br>\n",
    "val/<br>\n",
    "    ├── class_0/<br>\n",
    "    │   ├── ...<br>\n",
    "    │   └── all the fake images<br>\n",
    "    ├── class_1/<br>\n",
    "    │   ├── ...<br>\n",
    "    │   └── all the real images<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the collected data in the previously described structure\n",
    "\n",
    "from src.imageonly_detector.format_dataset import formatIntoDataset, formatIntoTrainTest\n",
    "\n",
    "#SD+MSCOCO\n",
    "#this function generates a pair of datasets (train and val), starting from data from the Stable Diffusion generation\n",
    "#the data generated from SD contains 100 images, this original dataset is split in half (50 for train, 50 for test)\n",
    "formatIntoTrainTest(\"data/MSCOCO_for_SD/images\", \"data/SD+MSCOCO/images\", \"data/imageonly_detector_data\")\n",
    "print(\"ok SD\")\n",
    "\n",
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "formatIntoDataset(\"data/MSCOCO_for_LD/images\", \"../latent-diffusion/outputs/txt2img-samples\", \"data/imageonly_detector_data/val_LD\")\n",
    "print(\"ok LD\")\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "formatIntoDataset(\"data/MSCOCO_for_GLIDE/images\", \"data/GLIDE+MSCOCO/images\", \"data/imageonly_detector_data/val_GLIDE\")\n",
    "print(\"ok GLIDE\")\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO (è a pagamento soltanto con le API, valutare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Detector\n",
    "\n",
    "The model is defined and trained in the file executed in the followind code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 100\n",
      "test dataset size: 98\n",
      "Epoch 0/49\n",
      "----------\n",
      "train Loss: 0.6691 Acc: 0.6200\n",
      "val Loss: 0.5134 Acc: 0.6837\n",
      "\n",
      "Epoch 1/49\n",
      "----------\n",
      "train Loss: 0.4941 Acc: 0.7400\n",
      "val Loss: 0.6277 Acc: 0.6939\n",
      "\n",
      "Epoch 2/49\n",
      "----------\n",
      "train Loss: 0.3981 Acc: 0.8000\n",
      "val Loss: 0.2936 Acc: 0.8571\n",
      "\n",
      "Epoch 3/49\n",
      "----------\n",
      "train Loss: 0.3812 Acc: 0.8300\n",
      "val Loss: 0.3056 Acc: 0.8776\n",
      "\n",
      "Epoch 4/49\n",
      "----------\n",
      "train Loss: 0.6900 Acc: 0.7600\n",
      "val Loss: 0.4617 Acc: 0.7755\n",
      "\n",
      "Epoch 5/49\n",
      "----------\n",
      "train Loss: 0.4494 Acc: 0.8100\n",
      "val Loss: 0.4298 Acc: 0.8163\n",
      "\n",
      "Epoch 6/49\n",
      "----------\n",
      "train Loss: 0.4004 Acc: 0.8500\n",
      "val Loss: 0.7959 Acc: 0.7449\n",
      "\n",
      "Epoch 7/49\n",
      "----------\n",
      "train Loss: 0.4696 Acc: 0.8400\n",
      "val Loss: 0.3766 Acc: 0.8571\n",
      "\n",
      "Epoch 8/49\n",
      "----------\n",
      "train Loss: 0.5092 Acc: 0.8000\n",
      "val Loss: 0.2665 Acc: 0.8878\n",
      "\n",
      "Epoch 9/49\n",
      "----------\n",
      "train Loss: 0.2969 Acc: 0.8600\n",
      "val Loss: 0.2440 Acc: 0.9286\n",
      "\n",
      "Epoch 10/49\n",
      "----------\n",
      "train Loss: 0.2016 Acc: 0.9200\n",
      "val Loss: 0.2715 Acc: 0.9184\n",
      "\n",
      "Epoch 11/49\n",
      "----------\n",
      "train Loss: 0.2869 Acc: 0.8900\n",
      "val Loss: 0.2229 Acc: 0.9286\n",
      "\n",
      "Epoch 12/49\n",
      "----------\n",
      "train Loss: 0.2093 Acc: 0.9000\n",
      "val Loss: 0.2195 Acc: 0.9388\n",
      "\n",
      "Epoch 13/49\n",
      "----------\n",
      "train Loss: 0.2751 Acc: 0.8800\n",
      "val Loss: 0.2254 Acc: 0.9388\n",
      "\n",
      "Epoch 14/49\n",
      "----------\n",
      "train Loss: 0.1403 Acc: 0.9500\n",
      "val Loss: 0.2362 Acc: 0.9184\n",
      "\n",
      "Epoch 15/49\n",
      "----------\n",
      "train Loss: 0.2880 Acc: 0.8600\n",
      "val Loss: 0.2258 Acc: 0.9286\n",
      "\n",
      "Epoch 16/49\n",
      "----------\n",
      "train Loss: 0.1946 Acc: 0.9100\n",
      "val Loss: 0.2104 Acc: 0.9184\n",
      "\n",
      "Epoch 17/49\n",
      "----------\n",
      "train Loss: 0.2022 Acc: 0.9200\n",
      "val Loss: 0.2203 Acc: 0.9286\n",
      "\n",
      "Epoch 18/49\n",
      "----------\n",
      "train Loss: 0.2169 Acc: 0.9000\n",
      "val Loss: 0.2138 Acc: 0.9286\n",
      "\n",
      "Epoch 19/49\n",
      "----------\n",
      "train Loss: 0.2913 Acc: 0.8600\n",
      "val Loss: 0.2143 Acc: 0.9388\n",
      "\n",
      "Epoch 20/49\n",
      "----------\n",
      "train Loss: 0.1548 Acc: 0.9300\n",
      "val Loss: 0.2233 Acc: 0.9286\n",
      "\n",
      "Epoch 21/49\n",
      "----------\n",
      "train Loss: 0.2143 Acc: 0.9200\n",
      "val Loss: 0.2202 Acc: 0.9184\n",
      "\n",
      "Epoch 22/49\n",
      "----------\n",
      "train Loss: 0.1789 Acc: 0.9400\n",
      "val Loss: 0.2288 Acc: 0.9388\n",
      "\n",
      "Epoch 23/49\n",
      "----------\n",
      "train Loss: 0.2271 Acc: 0.9100\n",
      "val Loss: 0.2032 Acc: 0.9184\n",
      "\n",
      "Epoch 24/49\n",
      "----------\n",
      "train Loss: 0.2806 Acc: 0.8800\n",
      "val Loss: 0.2016 Acc: 0.9286\n",
      "\n",
      "Epoch 25/49\n",
      "----------\n",
      "train Loss: 0.2749 Acc: 0.8900\n",
      "val Loss: 0.2213 Acc: 0.9286\n",
      "\n",
      "Epoch 26/49\n",
      "----------\n",
      "train Loss: 0.1535 Acc: 0.9000\n",
      "val Loss: 0.2141 Acc: 0.9286\n",
      "\n",
      "Epoch 27/49\n",
      "----------\n",
      "train Loss: 0.1280 Acc: 0.9500\n",
      "val Loss: 0.2302 Acc: 0.9184\n",
      "\n",
      "Epoch 28/49\n",
      "----------\n",
      "train Loss: 0.2825 Acc: 0.9000\n",
      "val Loss: 0.2114 Acc: 0.9286\n",
      "\n",
      "Epoch 29/49\n",
      "----------\n",
      "train Loss: 0.2400 Acc: 0.9200\n",
      "val Loss: 0.2221 Acc: 0.9184\n",
      "\n",
      "Epoch 30/49\n",
      "----------\n",
      "train Loss: 0.2824 Acc: 0.8500\n",
      "val Loss: 0.2146 Acc: 0.9286\n",
      "\n",
      "Epoch 31/49\n",
      "----------\n",
      "train Loss: 0.1646 Acc: 0.9300\n",
      "val Loss: 0.2127 Acc: 0.9286\n",
      "\n",
      "Epoch 32/49\n",
      "----------\n",
      "train Loss: 0.0886 Acc: 0.9700\n",
      "val Loss: 0.2310 Acc: 0.9082\n",
      "\n",
      "Epoch 33/49\n",
      "----------\n",
      "train Loss: 0.2712 Acc: 0.8700\n",
      "val Loss: 0.2099 Acc: 0.9286\n",
      "\n",
      "Epoch 34/49\n",
      "----------\n",
      "train Loss: 0.1435 Acc: 0.9600\n",
      "val Loss: 0.2202 Acc: 0.9286\n",
      "\n",
      "Epoch 35/49\n",
      "----------\n",
      "train Loss: 0.3852 Acc: 0.8900\n",
      "val Loss: 0.2159 Acc: 0.9388\n",
      "\n",
      "Epoch 36/49\n",
      "----------\n",
      "train Loss: 0.3126 Acc: 0.9100\n",
      "val Loss: 0.2112 Acc: 0.9286\n",
      "\n",
      "Epoch 37/49\n",
      "----------\n",
      "train Loss: 0.2386 Acc: 0.8900\n",
      "val Loss: 0.2350 Acc: 0.9286\n",
      "\n",
      "Epoch 38/49\n",
      "----------\n",
      "train Loss: 0.3077 Acc: 0.8800\n",
      "val Loss: 0.2035 Acc: 0.9286\n",
      "\n",
      "Epoch 39/49\n",
      "----------\n",
      "train Loss: 0.2621 Acc: 0.9000\n",
      "val Loss: 0.2572 Acc: 0.9082\n",
      "\n",
      "Epoch 40/49\n",
      "----------\n",
      "train Loss: 0.3718 Acc: 0.8400\n",
      "val Loss: 0.2114 Acc: 0.9286\n",
      "\n",
      "Epoch 41/49\n",
      "----------\n",
      "train Loss: 0.2080 Acc: 0.9100\n",
      "val Loss: 0.2106 Acc: 0.9286\n",
      "\n",
      "Epoch 42/49\n",
      "----------\n",
      "train Loss: 0.2027 Acc: 0.9100\n",
      "val Loss: 0.2077 Acc: 0.9286\n",
      "\n",
      "Epoch 43/49\n",
      "----------\n",
      "train Loss: 0.2036 Acc: 0.8900\n",
      "val Loss: 0.2162 Acc: 0.9286\n",
      "\n",
      "Epoch 44/49\n",
      "----------\n",
      "train Loss: 0.2680 Acc: 0.9000\n",
      "val Loss: 0.2220 Acc: 0.9286\n",
      "\n",
      "Epoch 45/49\n",
      "----------\n",
      "train Loss: 0.1973 Acc: 0.9200\n",
      "val Loss: 0.2160 Acc: 0.9388\n",
      "\n",
      "Epoch 46/49\n",
      "----------\n",
      "train Loss: 0.3268 Acc: 0.8400\n",
      "val Loss: 0.2445 Acc: 0.9286\n",
      "\n",
      "Epoch 47/49\n",
      "----------\n",
      "train Loss: 0.1738 Acc: 0.9300\n",
      "val Loss: 0.2101 Acc: 0.9388\n",
      "\n",
      "Epoch 48/49\n",
      "----------\n",
      "train Loss: 0.1846 Acc: 0.9200\n",
      "val Loss: 0.2038 Acc: 0.9388\n",
      "\n",
      "Epoch 49/49\n",
      "----------\n",
      "train Loss: 0.3314 Acc: 0.8700\n",
      "val Loss: 0.2186 Acc: 0.9388\n",
      "\n",
      "Training complete in 0m 50s\n",
      "Best val Acc: 0.938776\n",
      "val_LD Loss: 1.1028 Acc: 0.5700\n",
      "val_GLIDE Loss: 0.4627 Acc: 0.8400\n",
      "Evaluation complete in 0m 1s\n"
     ]
    }
   ],
   "source": [
    "#this function trains the model and tests it at every epoch\n",
    "#both the test and train datasets are generated using SD\n",
    "%run src/imageonly_detector/train.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hybrid detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Dataset\n",
    "\n",
    "The dataset is built in the exact same way as the dataset for the image-only detector.\n",
    "The following are the instructions to run in order to build:\n",
    "- one training dataset (using images generated from SD)\n",
    "- three evaluation dataset (using images generated from SD, LD and GLIDE respectively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=13.79s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.73s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=12.11s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.73s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=12.86s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.78s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=13.52s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.72s)\n",
      "creating index...\n",
      "index created!\n",
      "Your request activated the API's safety filters and could not be processed.Please modify the prompt and try again.\n",
      "Current prompt (detected invalid)s: A kid playing with a bat and ball on a beach.\n",
      "genero l'immagine 0/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 872.30 M params.\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 1/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 872.30 M params.\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 2/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 872.30 M params.\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 3/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 872.30 M params.\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 4/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 5/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 6/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 872.30 M params.\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 7/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 872.30 M params.\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 8/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 9/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 872.30 M params.\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 10/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 11/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 12/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 872.30 M params.\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 13/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 872.30 M params.\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 14/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 872.30 M params.\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 15/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 872.30 M params.\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 16/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 17/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "DiffusionWrapper has 872.30 M params.\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 18/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n",
      "-----------------------------------------------------\n",
      "genero l'immagine 19/50\n",
      "Loading model from models/ldm/text2img-large/model.ckpt\n",
      "LatentDiffusion: Running in eps-prediction mode\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# N.B.\n",
    "# before running this block you need to erase all the content of the following directories:\n",
    "# data/MSCOCO_for_SD\n",
    "# data/MSCOCO_for_LD\n",
    "# data/MSCOCO_for_GLIDE\n",
    "# data/SD+MSCOCO\n",
    "# data/GLIDE+MSCOCO\n",
    "# latent-diffusion/outputs/txt2img-samples\n",
    "\n",
    "# ------------------- COLLECT REAL IMAGES FROM MSCOCO -------------------- #\n",
    "#import the path to the scripts needed for this section\n",
    "sys.path.insert(10, '/home/parwal/Documents/GitHub/De-Fake_nn_final_project/src/imageonly_detector')\n",
    "#TODO capire a chi serve questo import e metterlo nel posto giusto\n",
    "\n",
    "from src.imageonly_detector.MSCOCO_data_collection import fetchImagesFromMSCOCO\n",
    "\n",
    "#SD+MSCOCO\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_SD/images\", \"data/MSCOCO_for_SD\", 100)\n",
    "\n",
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_LD/images\", \"data/MSCOCO_for_LD\", 50)\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "fetchImagesFromMSCOCO(\"data/MSCOCO_for_GLIDE/images\", \"data/MSCOCO_for_GLIDE\", 50)\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# ------------------- GENERATE FAKE IMAGES USING SD, LD, GLIDE -------------------- #\n",
    "#SD+MSCOCO --------------------------------------------------------------------------\n",
    "#use stable-diffusion API to generate 100 fake images from the 100 captions collected before\n",
    "%run src/imageonly_detector/SD_MSCOCO_data_generation.py\n",
    "\n",
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "# N.B.\n",
    "# prima di lanciare questo comando, aggiungere il file src/imageonly_detector/txt2img_batch.py alla directory latent-diffusion/scripts/\n",
    "#resetto la directory corrente a quella del progetto de-fake, altrimenti il file da eseguire non viene trovato\n",
    "#questo è necessario perché LD_MSCOCO_data_generation.py cambia la directory a quella di latent-diffusion\n",
    "os.chdir(\"/home/parwal/Documents/GitHub/De-Fake_nn_final_project\")\n",
    "%run src/imageonly_detector/LD_MSCOCO_data_generation_batch.py\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "#NON HO MAI PROVATO A RUNNARLO, altrimenti rigenera il modello (3gb)\n",
    "#provare a runnarlo proprio alla fine di tutto per sicurezza\n",
    "%run src/imageonly_detector/GLIDE_MSCOCO_data_generation.ipynb #TODO\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO (è a pagamento soltanto con le API, valutare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# ------------------- FORMAT THE DATA INTO THE STRUCTURE NEEDED FOR TRAINING/TESTING -------------------- #\n",
    "os.chdir(\"/home/parwal/Documents/GitHub/De-Fake_nn_final_project\")\n",
    "\n",
    "#transform the collected data in the previously described structure\n",
    "from src.imageonly_detector.format_dataset import formatIntoDataset, formatIntoTrainTest\n",
    "\n",
    "\n",
    "#SD+MSCOCO --------------------------------------------------------------------------\n",
    "#this function generates a pair of datasets (train and val), starting from data from the Stable Diffusion generation\n",
    "#the data generated from SD contains 100 images, this original dataset is split in half (50 for train, 50 for test)\n",
    "formatIntoTrainTest(\"data/MSCOCO_for_SD/images\", \"data/SD+MSCOCO/images\", \"data/hybrid_detector_data\")\n",
    "print(\"ok SD\")\n",
    "\n",
    "#LD+MSCOCO --------------------------------------------------------------------------\n",
    "formatIntoDataset(\"data/MSCOCO_for_LD/images\", \"../latent-diffusion/outputs/txt2img-samples\", \"data/hybrid_detector_data/val_LD\")\n",
    "print(\"ok LD\")\n",
    "\n",
    "#GLIDE+MSCOCO -----------------------------------------------------------------------\n",
    "formatIntoDataset(\"data/MSCOCO_for_GLIDE/images\", \"data/GLIDE+MSCOCO/images\", \"data/hybrid_detector_data/val_GLIDE\") #TODO\n",
    "print(\"ok GLIDE\")\n",
    "\n",
    "#DALL-E2+MSCOCO ---------------------------------------------------------------------\n",
    "#TODO (è a pagamento soltanto con le API, valutare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ2. Attribution of the fake images to their source model\n",
    "\n",
    "The study proposes two attributor models:\n",
    "\n",
    "1. **Image-only attributor**<br>multi-class classifier that assigns each input image to its source generation model.\n",
    "\n",
    "2. **Hybrid attributor**<br>multi-class classifier that assigns each input image to its source generation model, based on the input image and its corresponding text prompt.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Image-only attributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hybrid attributor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ3. Analysis of the likelihood that different text prompts have to generate authentic images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
